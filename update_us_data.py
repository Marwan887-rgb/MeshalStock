import yfinance as yf
import pandas as pd
import os
import time
from datetime import datetime, timedelta
from io import StringIO

# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
DATA_DIR = 'data_us'
LOG_FILE = 'us_data_update.log'
COLUMNS = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']

# --- Ø§Ù„Ø¯Ø§Ù„Ø§Øª ---

def setup_logging():
    """Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« ÙÙŠ Ù…Ù„Ù ÙˆØ³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø±."""
    def log(message):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_message = f"[{timestamp}] {message}"
        print(log_message)
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            f.write(log_message + '\n')
    return log

def read_and_clean_csv(file_path, log):
    """
    ÙŠÙ‚Ø±Ø£ Ù…Ù„Ù CSVØŒ ÙˆÙŠÙ†Ø¸ÙÙ‡ØŒ ÙˆÙŠÙˆØ­Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙˆØ§ÙÙ‚.
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ÙØ§Ø±ØºØ© ØªÙ…Ø§Ù…Ø§Ù‹
            lines = [line for line in f if line.strip() and line.strip() != ',,,,,']
        
        if not lines:
            return None

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„ØªØ±ÙˆÙŠØ³Ø© Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ù† Ø£ÙŠÙ† ØªØ¨Ø¯Ø£ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©
        has_header = 'date' in lines[0].lower()
        start_row = 1 if has_header else 0
        
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¯ÙˆÙ† ØªØ±ÙˆÙŠØ³Ø© ÙˆÙØ±Ø¶ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©
        df = pd.read_csv(StringIO("\n".join(lines[start_row:])), header=None, names=COLUMNS)

        # --- ØªÙ†Ø¸ÙŠÙ ÙˆØªÙˆØ­ÙŠØ¯ Ø´Ø§Ù…Ù„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
        # 1. ØªØ­ÙˆÙŠÙ„ Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø£Ø®Ø·Ø§Ø¡
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        
        # 2. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù†ØµÙˆØµ
        for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # 3. Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ ØµÙÙˆÙ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… ÙØ§Ø±ØºØ© ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        df.dropna(subset=COLUMNS, inplace=True)
        
        # 4. Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØµØ­ÙŠØ­ (Volume ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø¹Ø¯Ø¯Ù‹Ø§ ØµØ­ÙŠØ­Ù‹Ø§)
        if 'Volume' in df.columns and not df.empty:
            df['Volume'] = df['Volume'].astype(int)

        return df

    except Exception as e:
        log(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© ÙˆØªÙ†Ø¸ÙŠÙ {os.path.basename(file_path)}: {e}")
        return None


def update_stock_data(log):
    """ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ù‡Ù… Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©."""
    log("=== Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ ===")
    
    if not os.path.exists(DATA_DIR):
        log(f"Ø®Ø·Ø£: Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª '{DATA_DIR}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
        return

    files_to_update = [f for f in os.listdir(DATA_DIR) if f.endswith('.csv')]
    total_files = len(files_to_update)
    
    if total_files == 0:
        log("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª Ù„ØªØ­Ø¯ÙŠØ«Ù‡Ø§.")
        return
        
    log(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {total_files} Ù…Ù„Ù Ù„ØªØ­Ø¯ÙŠØ«Ù‡.")

    # Ù„Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ø­Ø§Ù„ÙŠØŒ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ØªØ§Ø±ÙŠØ® Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ù‡Ùˆ Ø§Ù„ØºØ¯
    end_date = datetime.now() + timedelta(days=1)

    for i, filename in enumerate(files_to_update):
        symbol = filename.replace('.csv', '')
        file_path = os.path.join(DATA_DIR, filename)
        log(f"--- ({i+1}/{total_files}) Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© {symbol} ---")

        try:
            df = read_and_clean_csv(file_path, log)
            
            if df is None or df.empty:
                log(f"âš ï¸ Ø§Ù„Ù…Ù„Ù {filename} ÙØ§Ø±Øº Ø£Ùˆ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ. Ø³ÙŠØªÙ… ØªØ®Ø·ÙŠÙ‡.")
                continue
            
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ù…Ø±ØªØ¨Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢Ø®Ø± ØªØ§Ø±ÙŠØ®
            df.sort_values(by='Date', inplace=True)
            last_date = df['Date'].max()
            start_date = last_date + timedelta(days=1)

            # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø§Ù„ÙˆÙ‚Øª
            if start_date.date() >= datetime.now().date():
                log(f"âœ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€ {symbol} Ù…Ø­Ø¯Ø«Ø© Ø¨Ø§Ù„ÙØ¹Ù„.")
                # Ù†Ø¹ÙŠØ¯ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ù†Ø¸Ø§ÙØªÙ‡ ÙˆØªÙ†Ø³ÙŠÙ‚Ù‡ Ø§Ù„Ù…ÙˆØ­Ø¯
                df.to_csv(file_path, index=False, header=True)
                continue

            log(f"Ø¢Ø®Ø± ØªØ§Ø±ÙŠØ®: {last_date.strftime('%Y-%m-%d')}. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† {start_date.strftime('%Y-%m-%d')}")

            new_data = yf.download(
                tickers=symbol,
                start=start_date.strftime('%Y-%m-%d'),
                end=end_date.strftime('%Y-%m-%d'),
                auto_adjust=False,
                progress=False
            )

            if new_data.empty:
                log(f"Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù€ {symbol}.")
                # Ù†Ø¹ÙŠØ¯ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ù„Ø¶Ù…Ø§Ù† ØªÙ†Ø³ÙŠÙ‚Ù‡ Ø­ØªÙ‰ Ù„Ùˆ Ù„Ù… ÙŠØªØºÙŠØ± Ø´ÙŠØ¡
                df.to_csv(file_path, index=False, header=True)
                continue
            
            new_data.reset_index(inplace=True)
            
            # ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙ‚Ø· Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
            new_data = new_data[[col for col in COLUMNS if col in new_data.columns]]

            combined_df = pd.concat([df, new_data], ignore_index=True)
            combined_df.drop_duplicates(subset=['Date'], keep='last', inplace=True)
            combined_df.sort_values(by='Date', inplace=True)
            
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø­ÙØ¸
            for col in ['Open', 'High', 'Low', 'Close']:
                 combined_df[col] = pd.to_numeric(combined_df[col])
            combined_df['Volume'] = pd.to_numeric(combined_df['Volume'])
            combined_df.dropna(inplace=True)
            
            if 'Volume' in combined_df.columns and not combined_df.empty:
                combined_df['Volume'] = combined_df['Volume'].astype(int)

            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù…Ø¹ Ø§Ù„ØªØ±ÙˆÙŠØ³Ø©
            combined_df.to_csv(file_path, index=False, header=True)
            
            log(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« {symbol} Ø¨Ù€ {len(new_data)} ØµÙ Ø¬Ø¯ÙŠØ¯.")

        except pd.errors.EmptyDataError:
            log(f"âš ï¸ Ø§Ù„Ù…Ù„Ù {filename} ÙØ§Ø±Øº. Ø³ÙŠØªÙ… ØªØ®Ø·ÙŠÙ‡.")
        except Exception as e:
            log(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« {symbol}: {e}")
        
        time.sleep(1)

    log("ğŸ‰ Ø§Ù†ØªÙ‡Øª Ø¹Ù…Ù„ÙŠØ© ØªØ­Ø¯ÙŠØ« Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ.")

if __name__ == "__main__":
    log = setup_logging()
    update_stock_data(log)
